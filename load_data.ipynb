{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3Og3nBSkLw2"
   },
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwun_sjYkKpG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import gc\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "atrI8O4Z9FDc",
    "outputId": "a17d47d8-cbbe-4d66-d533-2d3036ffb3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10kB 13.8MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 40kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 51kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61kB 4.0MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 71kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 81kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 92kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 102kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 112kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 122kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 133kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 143kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 153kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 163kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 174kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 184kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 194kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 204kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 215kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 225kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 235kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 245kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 256kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 266kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 276kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 286kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 296kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 307kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 317kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 327kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 337kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 348kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 358kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 368kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 378kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 389kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 399kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 409kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 419kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 430kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 440kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 450kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 460kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 471kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 481kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 491kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 501kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 512kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 522kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 532kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 542kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 552kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 563kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 573kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 583kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 593kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 604kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 614kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 624kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 634kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 645kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 655kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 665kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 675kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 686kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 696kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 706kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 716kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 727kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 737kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 747kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 757kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 768kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 778kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 788kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 798kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 808kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 819kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 829kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 839kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 849kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 860kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 870kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 880kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 890kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 901kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 911kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 921kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 931kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 942kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 952kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 962kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 972kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 983kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 993kB 4.6MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Code to read csv file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "link = 'https://drive.google.com/open?id=10oIdF6PKPQowk5jCo6wYYIbeFXmAsw0z'\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('data.csv') \n",
    "\n",
    "link = 'https://drive.google.com/open?id=18XwATSUD1JO2JE5x88igCREM2FJqT8DO'\n",
    "fluff, id = link.split('=')\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('word_count_by_question.csv') \n",
    "\n",
    "\n",
    "link = 'https://drive.google.com/open?id=1Iaf0xaW1kfRwlPl1NirgT_hGAq__-Jwh'\n",
    "fluff, id = link.split('=')\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('word_count_total.csv') \n",
    "\n",
    "\n",
    "link = 'https://drive.google.com/open?id=12vuzZSJONTKVzylbuJVDvOgDyCMTJdEt'\n",
    "fluff, id = link.split('=')\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('city_information.tsv') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDdhmHRJm87Z"
   },
   "outputs": [],
   "source": [
    "#pour savoir quelle question correspond à quel numéro \n",
    "def question() : \n",
    "  l = []\n",
    "  l.append('Titre')\n",
    "  l.append('Quel est aujourdhui pour vous le problème concret le plus important dans le domaine de lenvironnement')\n",
    "  l.append('que faudrait-il faire pour apporter reponses au probleme le plus important dans le domaine environnement (suit question1)')\n",
    "  l.append('vie quotidienne impactée par changement climatique ? ')\n",
    "  l.append('quelle maniere vie quotidienne impactée changement climatique')\n",
    "  l.append('pensez-vous pouvoir contribuer à protéger environnement')\n",
    "  l.append('que faites vous aujourdhui pr environnement/ que pourriez vous faire')\n",
    "  l.append('questce qui peut vous inciter à changer comportement (ex chauffage, conduire, voiture courte distance')\n",
    "  l.append('solutions plus simples; plus supportables financierement pr inciter changer comportement')\n",
    "  l.append('par rapprt mode de chauffage actuel, pensez vous solutions alternatives plus écolo ? ')\n",
    "  l.append('que faut il faire pour vous faire changer mode de chauffage')\n",
    "  l.append('possibiité recourir mobilité alternative à voiture individuelle ?')\n",
    "  l.append('que faire pour vous convaincre pas utiliser voiture QCM')\n",
    "  l.append('quelles solutions mobilité alternatives aimerez vous utiliser (si yen avait)')\n",
    "  l.append('qui doit se charger proposer mobilité alternatives')\n",
    "  l.append('que faire france partager ses choix environnement niveau européen, international')\n",
    "  l.append('autre points ?')\n",
    "  \n",
    "  return(l)\n",
    "\n",
    "\n",
    "questions = question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWjvghzMkay6"
   },
   "source": [
    "# Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "df0OUTNm1oIf"
   },
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "def sort_dictionary(dictionary):\n",
    "    '''returns a sorted dictionary (as tuples) based on the value of each key'''\n",
    "    return sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def normalize_counts(counts):\n",
    "    '''returns the frequency of tokens for each text'''\n",
    "    total = sum(counts.values())\n",
    "    return dict((word, float(count)/total) for word,count in counts.items())\n",
    "  \n",
    "def read_data(filename,yes_no_array,by_frequency=True):\n",
    "    '''return an array of cleaned data from a csv file made by the write_data function.\n",
    "    The order of the columns is the following: \n",
    "    Title | Category of the participant | Questions | Output\n",
    "    INPUT: name of the file, position of the integer columns\n",
    "    OUTPUT: matrix of data'''\n",
    "    data = []\n",
    "    with open(filename, newline='',encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            element = []\n",
    "            for i in range(len(row)-1):\n",
    "              if i in yes_no_array:\n",
    "                element.append(int(row[i]))\n",
    "              elif by_frequency is True:\n",
    "                element.append(normalize_counts(read_dictionary(row[i])))\n",
    "              else:\n",
    "                element.append(read_dictionary(row[i]))\n",
    "            element.append(row.pop())\n",
    "            data.append(element)\n",
    "        #  call the garbage collector\n",
    "        gc.collect()\n",
    "    return data\n",
    "\n",
    "def read_word_count(filename):\n",
    "    '''This function reads a file which contains arrays of tuples of key and number of occurrences\n",
    "    of a word, and returns an array of dictionaries with the tuples\n",
    "    INPUT: name of the file to upload\n",
    "    OUTPUT: dictionnary with the words of the file'''\n",
    "    words = []\n",
    "    with open(filename, newline='',encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            dictionary = dict()\n",
    "            for i in row:\n",
    "                dictionary.update(read_dictionary(i))\n",
    "            words.append(dictionary)\n",
    "        #  call the garbage collector\n",
    "        gc.collect()\n",
    "    return words\n",
    "\n",
    "def read_dictionary(dictionary_string):\n",
    "    '''return a dictionary from a string \n",
    "    INPUT: an string of many key-value tuples\n",
    "    OUTPUT: a dictionary'''\n",
    "    dictionary = dict()\n",
    "    clean_dict = re.sub(r'[ \\[ | \\] | \\( | \\) | \\' | { | } ]','', dictionary_string)\n",
    "    parsed_dict = re.split(r'[,|:]', clean_dict)\n",
    "    for i in range(int(len(parsed_dict)/2)):\n",
    "        key = parsed_dict[2*i]\n",
    "        value = int(parsed_dict[2*i+1])\n",
    "        dictionary[key] = value\n",
    "    return dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZkYu02_kiPl"
   },
   "source": [
    "## Ajout de l'output et calcul des mots les plus utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLNVWBPC1oIj"
   },
   "outputs": [],
   "source": [
    "def find_zip_codes_by_town(density_threshold,filename='city_information.tsv'):\n",
    "    '''This function splits up the zip codes of a file into two categories according to a density threshold\n",
    "    INPUT: density threshold, file name of the reference library\n",
    "    OUTPUT: set of zip codes for cities, a set of zip codes for villages'''\n",
    "    codes_cities = set()\n",
    "    tmp_code_cities = set()\n",
    "    codes_villages = set()\n",
    "    tmp_code_villages = set()\n",
    "    with open(filename, newline='',encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            # We keep only the questions with a valid ID and a valid number of rows\n",
    "            density = -1\n",
    "            if row[3] != '' and row[4] != '':\n",
    "                density = float(row[3]) / float(row[4])\n",
    "            if density >= density_threshold:\n",
    "                codes_cities.add(row[1])\n",
    "            elif density != -1: codes_villages.add(row[1])\n",
    "    tmp_code_cities = codes_cities.copy()\n",
    "    tmp_code_villages = codes_villages.copy()\n",
    "    for code in tmp_code_cities:\n",
    "        match = re.search('-',code)\n",
    "        if (match != None):\n",
    "            codes_cities.remove(code)\n",
    "            split_codes = re.split('-', code)\n",
    "            for i in split_codes:\n",
    "                codes_cities.add(i)\n",
    "    for code in tmp_code_villages:\n",
    "        match = re.search('-',code)\n",
    "        if (match != None):\n",
    "            codes_villages.remove(code)\n",
    "            split_codes = re.split('-', code)\n",
    "            for i in split_codes:\n",
    "                codes_villages.add(i)\n",
    "    #  call the garbage collector\n",
    "    gc.collect()\n",
    "    return codes_cities,codes_villages\n",
    "\n",
    "def city_village_classifier(density_threshold,data):\n",
    "    '''This function tags the entries of a data set according to their population density. If it is more than\n",
    "    a given threshold, the label is 1, -1 otherwise\n",
    "    INPUT: the density threshold, a dataset\n",
    "    OUTPUT: the classified dataset'''\n",
    "    city_zip_codes , village_zip_codes = find_zip_codes_by_town(density_threshold)\n",
    "    classified_data = []\n",
    "    class_vector = []\n",
    "    for entry in data:\n",
    "        if entry[-1] in city_zip_codes:\n",
    "            classified_data.append(entry)\n",
    "            class_vector.append(1)\n",
    "        elif entry[-1] in village_zip_codes: \n",
    "            classified_data.append(entry)\n",
    "            class_vector.append(-1)\n",
    "    classified_data = np.array(classified_data)\n",
    "    classified_data = np.delete(classified_data,len(classified_data[0])-1,1)\n",
    "    class_vector = np.array(class_vector).reshape((len(class_vector),1))\n",
    "    classified_data = np.append(classified_data,class_vector,axis=1)\n",
    "    #  call the garbage collector\n",
    "    gc.collect()\n",
    "    return classified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYK_-mAd1oIn"
   },
   "outputs": [],
   "source": [
    "def word_count_by_question(data,yes_no_questions):\n",
    "    '''This function counts all the words of a data set by question(column) and arrange them into a dictionnary\n",
    "    INPUT:  dataset, the numbers columns of integers\n",
    "    OUTPUT: an array of dictionaries of the counted words\n",
    "    '''\n",
    "    word_count = []    \n",
    "    for i in range(len(data[0])-1):\n",
    "        if i not in yes_no_questions:\n",
    "            word_count.append(Counter())\n",
    "    j = 0\n",
    "    for i in range(len(data[0])-1):\n",
    "        if i not in yes_no_questions:\n",
    "            for entry in column(data,i): word_count[j] += Counter(entry)\n",
    "            j += 1\n",
    "    #  call the garbage collector\n",
    "    gc.collect()\n",
    "    return word_count\n",
    "  \n",
    "\n",
    "def word_count_total(dictionary_array):\n",
    "    '''This functions sums up all the words of a many texts represented by dictionaries\n",
    "    INPUT: an array of dictionaries\n",
    "    OUTPUT a dictionary with the count of all the words:\n",
    "    '''\n",
    "    total_words = Counter()\n",
    "    for question in dictionary_array: total_words += Counter(question)\n",
    "    return total_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7qtvKzL1oIr"
   },
   "outputs": [],
   "source": [
    "def get_most_used_words(data, yes_no_array, word_count_array, number_of_words):\n",
    "    '''This function compares for each entry and question the number of ocurrences of the most used\n",
    "    words in the respective question. This function limits the number of most used words in order to normalized\n",
    "    the output\n",
    "    INPUT: a data set, the answers whose response is an integer, an array with the total of words by questions\n",
    "    the maximum number of words to keep, \n",
    "    OUTPUT: the filtered dataset\n",
    "    '''\n",
    "    most_used_words = []\n",
    "    for question in word_count_array:\n",
    "        words_by_question = []\n",
    "        sorted_word_array = sort_dictionary(question)\n",
    "        for i in range(number_of_words):\n",
    "            words_by_question.append(sorted_word_array[i])\n",
    "        most_used_words.append(words_by_question)\n",
    "    \n",
    "    filtered_data = []\n",
    "    \n",
    "    for entry in data:\n",
    "        entry_array = []\n",
    "        j = 0\n",
    "        for i in range(len(entry)-1):\n",
    "            if i in yes_no_array:\n",
    "                entry_array.append(entry[i])\n",
    "            else:\n",
    "                words_rep_array = []\n",
    "                for word in most_used_words[j]:\n",
    "                    try:\n",
    "                        words_rep_array.append(entry[i][word[0]])\n",
    "                    except KeyError as error:\n",
    "                        words_rep_array.append(0)\n",
    "                entry_array.append(words_rep_array)\n",
    "                j += 1\n",
    "        entry_array.append(entry[-1])\n",
    "        filtered_data.append(entry_array)\n",
    "    \n",
    "    #  call the garbage collector\n",
    "    gc.collect()\n",
    "        \n",
    "    return filtered_data\n",
    "\n",
    "def get_set_features(data,column):\n",
    "    '''This function return a feature (column) of a dataset\n",
    "    '''\n",
    "    a_data = np.array(data)\n",
    "    features = a_data[:,column]\n",
    "    features = np.array([np.asarray(i) for i in features])\n",
    "    return features\n",
    "\n",
    "def get_total_most_used_words(data, yes_no_array, word_count_array, number_of_words,by_question=True):\n",
    "    '''This function compares for each entry and question the number of ocurrences of the most used\n",
    "    words in the respective question. This function limits the number of most used words in order to normalized\n",
    "    the output\n",
    "    INPUT: a data set, the answers whose response is an integer, an array with the total number of words\n",
    "    the maximum number of words to keep, \n",
    "    OUTPUT: the filtered dataset\n",
    "    '''\n",
    "    most_used_words = []\n",
    "    sorted_word_array = sort_dictionary(word_count_array)\n",
    "    for i in range(number_of_words):\n",
    "        most_used_words.append(sorted_word_array[i])\n",
    "    \n",
    "    filtered_data = []\n",
    "    for entry in data:\n",
    "        entry_array = []\n",
    "        j = 0\n",
    "        entry_words = word_count_by_question([entry],yes_no_array)\n",
    "        entry_words= word_count_total(entry_words)\n",
    "        words_rep_array = []\n",
    "        for word in most_used_words:\n",
    "            try:\n",
    "                words_rep_array.append(entry_words[word[0]])\n",
    "            except KeyError as error:\n",
    "                words_rep_array.append(0)\n",
    "        entry_array.append(words_rep_array)\n",
    "        j += 1\n",
    "        entry_array.append(entry[-1])\n",
    "        filtered_data.append(entry_array)\n",
    "\n",
    "    #  call the garbage collector\n",
    "    gc.collect()\n",
    "        \n",
    "    return filtered_data\n",
    "  \n",
    "def get_name_most_used_words(word_dictonary, word_number):\n",
    "  words = []\n",
    "  sorted_words = sort_dictionary(word_dictonary)\n",
    "  for i in range(word_number):\n",
    "    words.append(sorted_words[i][0])\n",
    "  return words\n",
    "\n",
    "def get_word_and_count(word_dictonary, word_number):\n",
    "  words = []\n",
    "  counts = []\n",
    "  sorted_words = sort_dictionary(word_dictonary)\n",
    "  for i in range(word_number):\n",
    "    words.append(sorted_words[i][0])\n",
    "    counts.append(sorted_words[i][1])\n",
    "  return words, counts\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSEfldC-1oIw"
   },
   "outputs": [],
   "source": [
    "# exemple\n",
    "yes_no_questions = [1,4,6,10,12] #question en OUI/NON et QCM\n",
    "nbre_words = 5 #nombre de mots les plus utilisés qu'on souhaite sélectionner\n",
    "data = read_data('data.csv',[1,4,6,10,12],by_frequency=False) #lire les mots les plus utilisés\n",
    "classified_data = city_village_classifier(10000,data) #lire les output\n",
    "#g = read_word_count('word_count_by_question.csv') #liste des dictionnaires des mots les plus utilisés par question\n",
    "#h = word_count_total(g) #mots les plus utilisés dans tout le dataset\n",
    "#filtered_data = get_most_used_words(classified_data,yes_no_questions,g,nbre_words)  #données avec les nbre_words mots les plus utilisés par question et l'output \n",
    "\n",
    "#get_name_most_used_words(g[2],5)\n",
    "#g[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hLetuAiblW6J"
   },
   "source": [
    "# Méthode 1 : extraction des features par mots les plus utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2aT5CHtpSZ8"
   },
   "outputs": [],
   "source": [
    "def extract_features(classified_data ,nbre_words,yes_no_questions =[1,4,6,10,12]) :\n",
    "  '''\n",
    "  \n",
    "  INPUT : les données avec output, le nombre de mots que l'ont souhaite sélectionner pour les features\n",
    "  \n",
    "  OUTPUT : \n",
    "  -X : les lignes sont les réponses les colones les features avec le nombre d'ocurrence pour les réponses texte et le code de la réponse pour les questions\n",
    "  oui/non et QCM\n",
    "  -y : -1 ou 1 selon le cluster pour chaque réponse \n",
    "  -Le nom des features features_name\n",
    "\n",
    "  '''\n",
    "  #first, let's get most used words in total (all questions taken into account): \n",
    "  g = read_word_count('word_count_by_question.csv')\n",
    "  h = dict(word_count_total(g))\n",
    "  most_used_total = get_name_most_used_words(h, nbre_words) #the string of the words selected here\n",
    "  print(most_used_total)\n",
    "  question_used = [[] for i in range(len(most_used_total))] #here we are going to store the questions that use this words\n",
    "\n",
    "  f = get_most_used_words(classified_data,yes_no_questions,g,nbre_words) #the features \n",
    "  \n",
    "  #initialisation of X\n",
    "  nbre_input = 18 # 2 eme feature = catégorie : on retire. dernière = output. \n",
    "  nbre_yes_no = len(yes_no_questions)\n",
    "  nbre_features =  nbre_yes_no + nbre_words*(nbre_input-1-nbre_yes_no +4) + nbre_words +1 #number of columns of X\n",
    "  feature_size = len(get_set_features(f,0)) #number of rows of X\n",
    "  X = np.array(np.zeros((feature_size,nbre_features)))   \n",
    "  print(X.shape)\n",
    "  \n",
    "  \n",
    "  y = get_set_features(f,18)\n",
    "  features_name = ['' for i in range(nbre_features)]\n",
    "  column_of_x = 0\n",
    "  count_text_questions = 0\n",
    "  num = 0\n",
    "  for i in range(nbre_input) : #on enlève l'output\n",
    "    print('processing question ' + str(num))\n",
    "    print('colum n° : ' + str(column_of_x))\n",
    "    if i ==2 : \n",
    "      print('')\n",
    "      # on ne fait rien car on ne veut pas de cette catégorie\n",
    "    elif i in yes_no_questions : \n",
    "      #get read of the catergory of the response in the number of the question\n",
    "      if i>2 : \n",
    "          num = i-1\n",
    "      else : \n",
    "        num = i\n",
    "      feature = get_set_features(f,i)\n",
    "      X[:,column_of_x] = feature\n",
    "      features_name[column_of_x] = 'yes_no Q' + str(num)+ ' '\n",
    "      column_of_x += 1 \n",
    "    else : \n",
    "      words = get_name_most_used_words(g[count_text_questions],nbre_words) #list of strings : words used for the question i we are processing\n",
    "      \n",
    "      for k in range(nbre_words) :\n",
    " \n",
    "        #get read of the catergory of the response in the number of the question\n",
    "        if i>2 : \n",
    "          num = i-1\n",
    "        else : \n",
    "          num = i\n",
    "            \n",
    "        feature = get_set_features(f,i)[:,k] #we take the kème column : coresponding to the word selected\n",
    "        word = words[k]\n",
    "        features_name[column_of_x] = 'text Q' + str(num) + ' '+ word+ ' '\n",
    "        X[:,column_of_x] = feature\n",
    "        column_of_x += 1 #as there are several columns for each question, we need an extra iterator for the column of X\n",
    "        \n",
    "        if num==4 or num==6 or num==10 or num== 12 : #we group the yes_noquestions and the question that follows\n",
    "          print('processing grouped question n°' + str(num))\n",
    "          print('colum n° : ' + str(column_of_x))\n",
    "          prev = X[:,column_of_x -1 - k ] # cf the \"if group\" that follows\n",
    "          feature = get_set_features(f,i)[:,k] #we take the kème row\n",
    "          word = words[k]\n",
    "          feature = [feature[i]*prev[i] for i in range(feature_size)]\n",
    "          features_name[column_of_x] = 'grouped' + str(num-1)+ ' with ' + str(num) + ' '+ word+ ' '\n",
    "          X[:,column_of_x] = feature\n",
    "          column_of_x += 1\n",
    "          \n",
    "        \n",
    "        #test if this word is in the most used ones : \n",
    "        if word in most_used_total : \n",
    "          w = most_used_total.index(word)\n",
    "          question_used[w].append(feature)\n",
    "        \n",
    "      count_text_questions +=1\n",
    "      \n",
    "      #let's add the total of use of the most used word in all questions : \n",
    "      \n",
    "  for l in range(len(most_used_total)) : \n",
    "    print('processing word' + most_used_total[l] + ' in all questions')\n",
    "    print('colum n° : ' + str(column_of_x))\n",
    "    \n",
    "    features_name[column_of_x] = 'word '+most_used_total[l]+ ' in all the questions '\n",
    "    \n",
    "    if len(question_used[l]) == 0 : \n",
    "      column_of_x += 1 #column of zeros\n",
    "      print('le mot ' +  most_used_total[l] + 'ne ressort dans aucune question')\n",
    "    else : \n",
    "      vect = np.zeros(feature_size)\n",
    "      \n",
    "      for v in question_used[l] : \n",
    "        vect = [vect[i]+v[i] for i in range(feature_size)] #add the total of the word detection in every question concerned\n",
    "       \n",
    "\n",
    "      X[:,column_of_x] = vect\n",
    "      features_name[column_of_x] = 'word '+most_used_total[l]+ ' in all the questions '\n",
    "      column_of_x += 1\n",
    "\n",
    "      \n",
    "      \n",
    "  #transport and 'commun' are very used, we try to sum them in an other feature to see if they can group\n",
    "  transport_en_commun = [question_used[0][0][i]+question_used[1][0][i] for i in range(feature_size)] #add a feature which is the sum of the use of transport and commun\n",
    "  X[:,column_of_x] = transport_en_commun\n",
    "  features_name[column_of_x] = 'transport en commun for all questions '\n",
    "  column_of_x += 1\n",
    "  \n",
    "  return X, y,features_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7769
    },
    "colab_type": "code",
    "id": "Nc9hSsHyMjvH",
    "outputId": "3c438bf7-c8c8-4e39-f13e-b26a00b748d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transport', 'commun', 'ecolog', 'fair', 'produit', 'voitur', 'consomm', 'etre', 'energ', 'utilis', 'tax', 'pollut', 'aid', 'faut', 'franc', 'climat', 'developp', 'velo', 'chang', 'etat', 'dechet', 'vehicul', 'exempl', 'electr', 'local', 'chauffag', 'grand', 'eau', 'vill', 'pay', 'solut', 'dej', 'econom', 'entrepris', 'pollu', 'environ', 'tri', 'mem', 'air', 'limit', 'deplac', 'transit', 'deregl', 'secheress', 'tre', 'import', 'incit', 'doit', 'biodiversit', 'plac', 'mettr', 'avoir', 'moyen', 'isol', 'arret', 'polit', 'espec', 'bio', 'prix', 'niveau', 'product', 'favoris', 'possibl', 'cru', 'cout', 'demand', 'trop', 'europeen', 'etc', 'covoiturag', 'prendr', 'peut', 'problem', 'disparit', 'citoyen', 'achat', 'reduir', 'bon', 'petit', 'vi', 'mod', 'part', 'invest', 'augment', 'solair', 'achet', 'nucleair', 'pourr', 'seul', 'mond', 'fais', 'region', 'train', 'financier', 'agricultur', 'an', 'don', 'electricit', 'faudr', 'beaucoup']\n",
      "(91898, 1706)\n",
      "processing question 0\n",
      "colum n° : 0\n",
      "processing question 0\n",
      "colum n° : 100\n",
      "processing question 1\n",
      "colum n° : 101\n",
      "\n",
      "processing question 1\n",
      "colum n° : 101\n",
      "processing question 2\n",
      "colum n° : 201\n",
      "processing question 3\n",
      "colum n° : 202\n",
      "processing grouped question n°4\n",
      "colum n° : 203\n",
      "processing grouped question n°4\n",
      "colum n° : 205\n",
      "processing grouped question n°4\n",
      "colum n° : 207\n",
      "processing grouped question n°4\n",
      "colum n° : 209\n",
      "processing grouped question n°4\n",
      "colum n° : 211\n",
      "processing grouped question n°4\n",
      "colum n° : 213\n",
      "processing grouped question n°4\n",
      "colum n° : 215\n",
      "processing grouped question n°4\n",
      "colum n° : 217\n",
      "processing grouped question n°4\n",
      "colum n° : 219\n",
      "processing grouped question n°4\n",
      "colum n° : 221\n",
      "processing grouped question n°4\n",
      "colum n° : 223\n",
      "processing grouped question n°4\n",
      "colum n° : 225\n",
      "processing grouped question n°4\n",
      "colum n° : 227\n",
      "processing grouped question n°4\n",
      "colum n° : 229\n",
      "processing grouped question n°4\n",
      "colum n° : 231\n",
      "processing grouped question n°4\n",
      "colum n° : 233\n",
      "processing grouped question n°4\n",
      "colum n° : 235\n",
      "processing grouped question n°4\n",
      "colum n° : 237\n",
      "processing grouped question n°4\n",
      "colum n° : 239\n",
      "processing grouped question n°4\n",
      "colum n° : 241\n",
      "processing grouped question n°4\n",
      "colum n° : 243\n",
      "processing grouped question n°4\n",
      "colum n° : 245\n",
      "processing grouped question n°4\n",
      "colum n° : 247\n",
      "processing grouped question n°4\n",
      "colum n° : 249\n",
      "processing grouped question n°4\n",
      "colum n° : 251\n",
      "processing grouped question n°4\n",
      "colum n° : 253\n",
      "processing grouped question n°4\n",
      "colum n° : 255\n",
      "processing grouped question n°4\n",
      "colum n° : 257\n",
      "processing grouped question n°4\n",
      "colum n° : 259\n",
      "processing grouped question n°4\n",
      "colum n° : 261\n",
      "processing grouped question n°4\n",
      "colum n° : 263\n",
      "processing grouped question n°4\n",
      "colum n° : 265\n",
      "processing grouped question n°4\n",
      "colum n° : 267\n",
      "processing grouped question n°4\n",
      "colum n° : 269\n",
      "processing grouped question n°4\n",
      "colum n° : 271\n",
      "processing grouped question n°4\n",
      "colum n° : 273\n",
      "processing grouped question n°4\n",
      "colum n° : 275\n",
      "processing grouped question n°4\n",
      "colum n° : 277\n",
      "processing grouped question n°4\n",
      "colum n° : 279\n",
      "processing grouped question n°4\n",
      "colum n° : 281\n",
      "processing grouped question n°4\n",
      "colum n° : 283\n",
      "processing grouped question n°4\n",
      "colum n° : 285\n",
      "processing grouped question n°4\n",
      "colum n° : 287\n",
      "processing grouped question n°4\n",
      "colum n° : 289\n",
      "processing grouped question n°4\n",
      "colum n° : 291\n",
      "processing grouped question n°4\n",
      "colum n° : 293\n",
      "processing grouped question n°4\n",
      "colum n° : 295\n",
      "processing grouped question n°4\n",
      "colum n° : 297\n",
      "processing grouped question n°4\n",
      "colum n° : 299\n",
      "processing grouped question n°4\n",
      "colum n° : 301\n",
      "processing grouped question n°4\n",
      "colum n° : 303\n",
      "processing grouped question n°4\n",
      "colum n° : 305\n",
      "processing grouped question n°4\n",
      "colum n° : 307\n",
      "processing grouped question n°4\n",
      "colum n° : 309\n",
      "processing grouped question n°4\n",
      "colum n° : 311\n",
      "processing grouped question n°4\n",
      "colum n° : 313\n",
      "processing grouped question n°4\n",
      "colum n° : 315\n",
      "processing grouped question n°4\n",
      "colum n° : 317\n",
      "processing grouped question n°4\n",
      "colum n° : 319\n",
      "processing grouped question n°4\n",
      "colum n° : 321\n",
      "processing grouped question n°4\n",
      "colum n° : 323\n",
      "processing grouped question n°4\n",
      "colum n° : 325\n",
      "processing grouped question n°4\n",
      "colum n° : 327\n",
      "processing grouped question n°4\n",
      "colum n° : 329\n",
      "processing grouped question n°4\n",
      "colum n° : 331\n",
      "processing grouped question n°4\n",
      "colum n° : 333\n",
      "processing grouped question n°4\n",
      "colum n° : 335\n",
      "processing grouped question n°4\n",
      "colum n° : 337\n",
      "processing grouped question n°4\n",
      "colum n° : 339\n",
      "processing grouped question n°4\n",
      "colum n° : 341\n",
      "processing grouped question n°4\n",
      "colum n° : 343\n",
      "processing grouped question n°4\n",
      "colum n° : 345\n",
      "processing grouped question n°4\n",
      "colum n° : 347\n",
      "processing grouped question n°4\n",
      "colum n° : 349\n",
      "processing grouped question n°4\n",
      "colum n° : 351\n",
      "processing grouped question n°4\n",
      "colum n° : 353\n",
      "processing grouped question n°4\n",
      "colum n° : 355\n",
      "processing grouped question n°4\n",
      "colum n° : 357\n",
      "processing grouped question n°4\n",
      "colum n° : 359\n",
      "processing grouped question n°4\n",
      "colum n° : 361\n",
      "processing grouped question n°4\n",
      "colum n° : 363\n",
      "processing grouped question n°4\n",
      "colum n° : 365\n",
      "processing grouped question n°4\n",
      "colum n° : 367\n",
      "processing grouped question n°4\n",
      "colum n° : 369\n",
      "processing grouped question n°4\n",
      "colum n° : 371\n",
      "processing grouped question n°4\n",
      "colum n° : 373\n",
      "processing grouped question n°4\n",
      "colum n° : 375\n",
      "processing grouped question n°4\n",
      "colum n° : 377\n",
      "processing grouped question n°4\n",
      "colum n° : 379\n",
      "processing grouped question n°4\n",
      "colum n° : 381\n",
      "processing grouped question n°4\n",
      "colum n° : 383\n",
      "processing grouped question n°4\n",
      "colum n° : 385\n",
      "processing grouped question n°4\n",
      "colum n° : 387\n",
      "processing grouped question n°4\n",
      "colum n° : 389\n",
      "processing grouped question n°4\n",
      "colum n° : 391\n",
      "processing grouped question n°4\n",
      "colum n° : 393\n",
      "processing grouped question n°4\n",
      "colum n° : 395\n",
      "processing grouped question n°4\n",
      "colum n° : 397\n",
      "processing grouped question n°4\n",
      "colum n° : 399\n",
      "processing grouped question n°4\n",
      "colum n° : 401\n",
      "processing question 4\n",
      "colum n° : 402\n",
      "processing question 5\n",
      "colum n° : 403\n",
      "processing grouped question n°6\n",
      "colum n° : 404\n",
      "processing grouped question n°6\n",
      "colum n° : 406\n",
      "processing grouped question n°6\n",
      "colum n° : 408\n",
      "processing grouped question n°6\n",
      "colum n° : 410\n",
      "processing grouped question n°6\n",
      "colum n° : 412\n",
      "processing grouped question n°6\n",
      "colum n° : 414\n",
      "processing grouped question n°6\n",
      "colum n° : 416\n",
      "processing grouped question n°6\n",
      "colum n° : 418\n",
      "processing grouped question n°6\n",
      "colum n° : 420\n",
      "processing grouped question n°6\n",
      "colum n° : 422\n",
      "processing grouped question n°6\n",
      "colum n° : 424\n",
      "processing grouped question n°6\n",
      "colum n° : 426\n",
      "processing grouped question n°6\n",
      "colum n° : 428\n",
      "processing grouped question n°6\n",
      "colum n° : 430\n",
      "processing grouped question n°6\n",
      "colum n° : 432\n",
      "processing grouped question n°6\n",
      "colum n° : 434\n",
      "processing grouped question n°6\n",
      "colum n° : 436\n",
      "processing grouped question n°6\n",
      "colum n° : 438\n",
      "processing grouped question n°6\n",
      "colum n° : 440\n",
      "processing grouped question n°6\n",
      "colum n° : 442\n",
      "processing grouped question n°6\n",
      "colum n° : 444\n",
      "processing grouped question n°6\n",
      "colum n° : 446\n",
      "processing grouped question n°6\n",
      "colum n° : 448\n",
      "processing grouped question n°6\n",
      "colum n° : 450\n",
      "processing grouped question n°6\n",
      "colum n° : 452\n",
      "processing grouped question n°6\n",
      "colum n° : 454\n",
      "processing grouped question n°6\n",
      "colum n° : 456\n",
      "processing grouped question n°6\n",
      "colum n° : 458\n",
      "processing grouped question n°6\n",
      "colum n° : 460\n",
      "processing grouped question n°6\n",
      "colum n° : 462\n",
      "processing grouped question n°6\n",
      "colum n° : 464\n",
      "processing grouped question n°6\n",
      "colum n° : 466\n",
      "processing grouped question n°6\n",
      "colum n° : 468\n",
      "processing grouped question n°6\n",
      "colum n° : 470\n",
      "processing grouped question n°6\n",
      "colum n° : 472\n",
      "processing grouped question n°6\n",
      "colum n° : 474\n",
      "processing grouped question n°6\n",
      "colum n° : 476\n",
      "processing grouped question n°6\n",
      "colum n° : 478\n",
      "processing grouped question n°6\n",
      "colum n° : 480\n",
      "processing grouped question n°6\n",
      "colum n° : 482\n",
      "processing grouped question n°6\n",
      "colum n° : 484\n",
      "processing grouped question n°6\n",
      "colum n° : 486\n",
      "processing grouped question n°6\n",
      "colum n° : 488\n",
      "processing grouped question n°6\n",
      "colum n° : 490\n",
      "processing grouped question n°6\n",
      "colum n° : 492\n",
      "processing grouped question n°6\n",
      "colum n° : 494\n",
      "processing grouped question n°6\n",
      "colum n° : 496\n",
      "processing grouped question n°6\n",
      "colum n° : 498\n",
      "processing grouped question n°6\n",
      "colum n° : 500\n",
      "processing grouped question n°6\n",
      "colum n° : 502\n",
      "processing grouped question n°6\n",
      "colum n° : 504\n",
      "processing grouped question n°6\n",
      "colum n° : 506\n",
      "processing grouped question n°6\n",
      "colum n° : 508\n",
      "processing grouped question n°6\n",
      "colum n° : 510\n",
      "processing grouped question n°6\n",
      "colum n° : 512\n",
      "processing grouped question n°6\n",
      "colum n° : 514\n",
      "processing grouped question n°6\n",
      "colum n° : 516\n",
      "processing grouped question n°6\n",
      "colum n° : 518\n",
      "processing grouped question n°6\n",
      "colum n° : 520\n",
      "processing grouped question n°6\n",
      "colum n° : 522\n",
      "processing grouped question n°6\n",
      "colum n° : 524\n",
      "processing grouped question n°6\n",
      "colum n° : 526\n",
      "processing grouped question n°6\n",
      "colum n° : 528\n",
      "processing grouped question n°6\n",
      "colum n° : 530\n",
      "processing grouped question n°6\n",
      "colum n° : 532\n",
      "processing grouped question n°6\n",
      "colum n° : 534\n",
      "processing grouped question n°6\n",
      "colum n° : 536\n",
      "processing grouped question n°6\n",
      "colum n° : 538\n",
      "processing grouped question n°6\n",
      "colum n° : 540\n",
      "processing grouped question n°6\n",
      "colum n° : 542\n",
      "processing grouped question n°6\n",
      "colum n° : 544\n",
      "processing grouped question n°6\n",
      "colum n° : 546\n",
      "processing grouped question n°6\n",
      "colum n° : 548\n",
      "processing grouped question n°6\n",
      "colum n° : 550\n",
      "processing grouped question n°6\n",
      "colum n° : 552\n",
      "processing grouped question n°6\n",
      "colum n° : 554\n",
      "processing grouped question n°6\n",
      "colum n° : 556\n",
      "processing grouped question n°6\n",
      "colum n° : 558\n",
      "processing grouped question n°6\n",
      "colum n° : 560\n",
      "processing grouped question n°6\n",
      "colum n° : 562\n",
      "processing grouped question n°6\n",
      "colum n° : 564\n",
      "processing grouped question n°6\n",
      "colum n° : 566\n",
      "processing grouped question n°6\n",
      "colum n° : 568\n",
      "processing grouped question n°6\n",
      "colum n° : 570\n",
      "processing grouped question n°6\n",
      "colum n° : 572\n",
      "processing grouped question n°6\n",
      "colum n° : 574\n",
      "processing grouped question n°6\n",
      "colum n° : 576\n",
      "processing grouped question n°6\n",
      "colum n° : 578\n",
      "processing grouped question n°6\n",
      "colum n° : 580\n",
      "processing grouped question n°6\n",
      "colum n° : 582\n",
      "processing grouped question n°6\n",
      "colum n° : 584\n",
      "processing grouped question n°6\n",
      "colum n° : 586\n",
      "processing grouped question n°6\n",
      "colum n° : 588\n",
      "processing grouped question n°6\n",
      "colum n° : 590\n",
      "processing grouped question n°6\n",
      "colum n° : 592\n",
      "processing grouped question n°6\n",
      "colum n° : 594\n",
      "processing grouped question n°6\n",
      "colum n° : 596\n",
      "processing grouped question n°6\n",
      "colum n° : 598\n",
      "processing grouped question n°6\n",
      "colum n° : 600\n",
      "processing grouped question n°6\n",
      "colum n° : 602\n",
      "processing question 6\n",
      "colum n° : 603\n"
     ]
    }
   ],
   "source": [
    "#select the number of words and run the features\n",
    "nbre_words = 100\n",
    "\n",
    "c = classified_data\n",
    "X, y,features_name = extract_features(classified_data = c, nbre_words = nbre_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1otDJl-mh7S"
   },
   "source": [
    "## Importance des features pour la méthode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14-HkOp4mggI"
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "Xps= X\n",
    "yp= y \n",
    "names = features_name\n",
    "\n",
    "# Import the necessary libraries first\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Feature extraction\n",
    "test = SelectKBest(score_func=mutual_info_classif, k=15)\n",
    "fit = test.fit(Xps,yp)\n",
    "\n",
    "# Summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "cont=0\n",
    "for a in fit.scores_:\n",
    "    if a>0.01:\n",
    "        cont=cont+1\n",
    "\n",
    "#revers indices\n",
    "indices = np.argsort(fit.scores_)[::-1]\n",
    "FeatureIndList=[]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "print\n",
    "for f in range(Xps.shape[1]):\n",
    "    print(str(f) + \". \" + names[indices[f]] + str(fit.scores_[indices[f]]))\n",
    "    if fit.scores_[indices[f]]>0.02:\n",
    "        FeatureIndList.append(indices[f])\n",
    "        \n",
    "print(Xps[:,FeatureIndList].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zXz5wkmmnk0"
   },
   "source": [
    "## Extraire les features utiles pour la visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1PbcFLaKUs0"
   },
   "outputs": [],
   "source": [
    "def extract_features_visu(classified_data ,nbre_words,yes_no_questions =[1,4,6,10,12]) :\n",
    "  \n",
    "  '''Get the input, the output and the names of the features\n",
    "  '''\n",
    "  #first, let's get most used words in total (all questions taken into account): \n",
    "  g = read_word_count('word_count_by_question.csv')\n",
    "  h = dict(word_count_total(g))\n",
    "  most_used_total = get_name_most_used_words(h, nbre_words) #the string of the words selected here\n",
    "  print(most_used_total)\n",
    " \n",
    "  f = get_most_used_words(classified_data,yes_no_questions,g,nbre_words) #the features \n",
    "  \n",
    "  #initialisation of X\n",
    "  \n",
    "  \n",
    "  nbre_features =  nbre_words + 1 #number of columns of X #delete +1  if you delete transport en commun\n",
    "  feature_size = len(get_set_features(f,0)) #number of rows of X\n",
    "  X = np.array(np.zeros((feature_size,nbre_features)))   \n",
    "  print(X.shape)\n",
    "  \n",
    "  \n",
    "  y = get_set_features(f,18)\n",
    "  features_name = ['' for i in range(nbre_features)]\n",
    "  column_of_x = 0\n",
    "  count_text_questions = 0\n",
    "  num = 0\n",
    "  nbre_input = 18\n",
    "  question_used = [[] for i in range(len(most_used_total))]\n",
    "  \n",
    "  for i in range(nbre_input) : #on enlève l'output\n",
    "    print('processing question ' + str(num))\n",
    "    print('colum n° : ' + str(column_of_x))\n",
    "    if i ==2 : \n",
    "      print('')\n",
    "      # on ne fait rien car on ne veut pas de cette catégorie\n",
    "    \n",
    "    if i not in yes_no_questions : \n",
    "      words = get_name_most_used_words(g[count_text_questions],nbre_words) #list of strings : words used for the question i we are processing\n",
    "\n",
    "      for k in range(nbre_words) :\n",
    "        #get read of the catergory of the response in the number of the question\n",
    "        if i>2 : \n",
    "          num = i-1\n",
    "        else : \n",
    "          num = i\n",
    "\n",
    "        feature = get_set_features(f,i)[:,k] #we take the kème column : coresponding to the word selected\n",
    "        word = words[k]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          #test if this word is in the most used ones : \n",
    "        if word in most_used_total : \n",
    "          w = most_used_total.index(word)\n",
    "          question_used[w].append(feature)\n",
    "\n",
    "      count_text_questions +=1\n",
    "\n",
    "      #let's add the total of use of the most used word in all questions : \n",
    "      \n",
    "  for l in range(len(most_used_total)) : \n",
    "    print('processing word' + most_used_total[l] + ' in all questions')\n",
    "    print('colum n° : ' + str(column_of_x))\n",
    "    \n",
    "    features_name[column_of_x] = 'word '+most_used_total[l]+ ' in all the questions '\n",
    "    \n",
    "    if len(question_used[l]) == 0 : \n",
    "      column_of_x += 1 #column of zeros\n",
    "      print('le mot ' +  most_used_total[l] + 'ne ressort dans aucune question')\n",
    "    else : \n",
    "      vect = np.zeros(feature_size)\n",
    "      \n",
    "      for v in question_used[l] : \n",
    "        vect = [vect[i]+v[i] for i in range(feature_size)] #add the total of the word detection in every question concerned\n",
    "       \n",
    "\n",
    "    X[:,column_of_x] = vect\n",
    "    features_name[column_of_x] = 'word '+most_used_total[l]+ ' in all the questions '\n",
    "    column_of_x += 1\n",
    "\n",
    "      \n",
    "      \n",
    "  #transport and 'commun' are very used, we try to sum them in an other feature to see if they can group\n",
    "  transport_en_commun = [question_used[0][0][i]+question_used[1][0][i] for i in range(feature_size)] #add a feature which is the sum of the use of transport and commun\n",
    "  X[:,column_of_x] = transport_en_commun\n",
    "  features_name[column_of_x] = 'transport en commun for all questions '\n",
    "  column_of_x += 1\n",
    "  \n",
    "  return X, y,features_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "rqy9dqF40H1i",
    "outputId": "7035e480-181d-4747-ef9e-d61880ce7eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transport', 'commun', 'ecolog', 'fair', 'produit', 'voitur', 'consomm', 'etre', 'energ', 'utilis', 'tax', 'pollut', 'aid', 'faut', 'franc', 'climat', 'developp', 'velo', 'chang', 'etat', 'dechet', 'vehicul', 'exempl', 'electr', 'local', 'chauffag', 'grand', 'eau', 'vill', 'pay', 'solut', 'dej', 'econom', 'entrepris', 'pollu', 'environ', 'tri', 'mem', 'air', 'limit', 'deplac', 'transit', 'deregl', 'secheress', 'tre', 'import', 'incit', 'doit', 'biodiversit', 'plac', 'mettr', 'avoir', 'moyen', 'isol', 'arret', 'polit', 'espec', 'bio', 'prix', 'niveau', 'product', 'favoris', 'possibl', 'cru', 'cout', 'demand', 'trop', 'europeen', 'etc', 'covoiturag', 'prendr', 'peut', 'problem', 'disparit', 'citoyen', 'achat', 'reduir', 'bon', 'petit', 'vi', 'mod', 'part', 'invest', 'augment', 'solair', 'achet', 'nucleair', 'pourr', 'seul', 'mond', 'fais', 'region', 'train', 'financier', 'agricultur', 'an', 'don', 'electricit', 'faudr', 'beaucoup']\n",
      "(91898, 101)\n",
      "processing question 0\n",
      "colum n° : 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c0b931c3653e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassified_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features_visu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassified_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbre_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbre_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-a47506bdb3b1>\u001b[0m in \u001b[0;36mextract_features_visu\u001b[0;34m(classified_data, nbre_words, yes_no_questions)\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_set_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#we take the kème column : coresponding to the word selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f90aa3b93dc0>\u001b[0m in \u001b[0;36mget_set_features\u001b[0;34m(data, column)\u001b[0m\n\u001b[1;32m     43\u001b[0m     '''This function return a feature (column) of a dataset\n\u001b[1;32m     44\u001b[0m     '''\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0ma_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "nbre_words = 100\n",
    "\n",
    "c = classified_data\n",
    "X, y,features_name = extract_features_visu(classified_data = c, nbre_words = nbre_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-fQ8gZvXohsi",
    "outputId": "8a4d798e-e24b-4a44-ad12-34e0b82c854d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['commun', 'ecolog', 'fair', 'produit', 'voitur', 'consomm', 'etre', 'energ', 'utilis', 'tax', 'pollut', 'aid', 'faut', 'franc', 'climat', 'developp', 'velo', 'chang', 'etat', 'dechet', 'vehicul', 'exempl', 'electr', 'local', 'chauffag', 'grand', 'eau', 'vill', 'pay']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feat_array = np.array(X[:,-nbre_words-1:-1])\n",
    "\n",
    "top_names = [f.split(' ')[1] for f in features_name[-nbre_words-1:-1]]\n",
    "print(top_names)\n",
    "\n",
    "features_df = pd.DataFrame(data=feat_array,columns=top_names)\n",
    "features_df.to_csv('most_used_words_30.csv', sep=',', mode='w',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "09TdYkHrRJ-_",
    "outputId": "f6c601c9-6f62-423a-a1c9-4894d49c6344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text Q0 ecolog ', 'text Q0 transit ', 'text Q0 transport ', 'text Q0 environ ', 'text Q0 tax ', 'text Q0 energ ', 'text Q0 planet ', 'text Q0 climat ', 'text Q0 pollut ', 'text Q0 chang ', 'yes_no Q1 ', 'text Q2 climat ', 'text Q2 deregl ', 'text Q2 secheress ', 'text Q2 cru ', 'text Q2 pollut ', 'text Q2 air ', 'text Q2 biodiversit ', 'text Q2 espec ', 'text Q2 disparit ', 'text Q2 problem ', 'yes_no Q3 ', 'text Q4 transport ', 'grouped3 with 4 transport ', 'text Q4 produit ', 'grouped3 with 4 produit ', 'text Q4 tax ', 'grouped3 with 4 tax ', 'text Q4 energ ', 'grouped3 with 4 energ ', 'text Q4 developp ', 'grouped3 with 4 developp ', 'text Q4 fair ', 'grouped3 with 4 fair ', 'text Q4 consomm ', 'grouped3 with 4 consomm ', 'text Q4 etre ', 'grouped3 with 4 etre ', 'text Q4 ecolog ', 'grouped3 with 4 ecolog ', 'text Q4 faut ', 'grouped3 with 4 faut ', 'yes_no Q5 ', 'text Q6 pollut ', 'grouped5 with 6 pollut ', 'text Q6 climat ', 'grouped5 with 6 climat ', 'text Q6 ete ', 'grouped5 with 6 ete ', 'text Q6 secheress ', 'grouped5 with 6 secheress ', 'text Q6 air ', 'grouped5 with 6 air ', 'text Q6 saison ', 'grouped5 with 6 saison ', 'text Q6 chang ', 'grouped5 with 6 chang ', 'text Q6 temperatur ', 'grouped5 with 6 temperatur ', 'text Q6 canicul ', 'grouped5 with 6 canicul ', 'text Q6 eau ', 'grouped5 with 6 eau ', 'text Q7 tri ', 'text Q7 consomm ', 'text Q7 dechet ', 'text Q7 produit ', 'text Q7 utilis ', 'text Q7 voitur ', 'text Q7 eau ', 'text Q7 transport ', 'text Q7 local ', 'text Q7 deplac ', 'text Q8 transport ', 'text Q8 commun ', 'text Q8 dej ', 'text Q8 voitur ', 'text Q8 chauffag ', 'text Q8 vehicul ', 'text Q8 aid ', 'text Q8 fair ', 'text Q8 chang ', 'text Q8 electr ', 'yes_no Q9 ', 'text Q10 aid ', 'grouped9 with 10 aid ', 'text Q10 transport ', 'grouped9 with 10 transport ', 'text Q10 tax ', 'grouped9 with 10 tax ', 'text Q10 produit ', 'grouped9 with 10 produit ', 'text Q10 commun ', 'grouped9 with 10 commun ', 'text Q10 chang ', 'grouped9 with 10 chang ', 'text Q10 voitur ', 'grouped9 with 10 voitur ', 'text Q10 vehicul ', 'grouped9 with 10 vehicul ', 'text Q10 fair ', 'grouped9 with 10 fair ', 'text Q10 ecolog ', 'grouped9 with 10 ecolog ', 'yes_no Q11 ', 'text Q12 aid ', 'grouped11 with 12 aid ', 'text Q12 chauffag ', 'grouped11 with 12 chauffag ', 'text Q12 solair ', 'grouped11 with 12 solair ', 'text Q12 chang ', 'grouped11 with 12 chang ', 'text Q12 isol ', 'grouped11 with 12 isol ', 'text Q12 financier ', 'grouped11 with 12 financier ', 'text Q12 energ ', 'grouped11 with 12 energ ', 'text Q12 chaudier ', 'grouped11 with 12 chaudier ', 'text Q12 install ', 'grouped11 with 12 install ', 'text Q12 panneau ', 'grouped11 with 12 panneau ', 'text Q13 transport ', 'text Q13 commun ', 'text Q13 voitur ', 'text Q13 velo ', 'text Q13 utilis ', 'text Q13 bus ', 'text Q13 cyclabl ', 'text Q13 vill ', 'text Q13 pist ', 'text Q13 developp ', 'text Q14 transport ', 'text Q14 commun ', 'text Q14 velo ', 'text Q14 demand ', 'text Q14 covoiturag ', 'text Q14 partag ', 'text Q14 auto ', 'text Q14 voitur ', 'text Q14 electr ', 'text Q14 vehicul ', 'text Q15 etat ', 'text Q15 commun ', 'text Q15 region ', 'text Q15 collectivit ', 'text Q15 transport ', 'text Q15 depart ', 'text Q15 local ', 'text Q15 entrepris ', 'text Q15 mair ', 'text Q15 vill ', 'text Q16 exempl ', 'text Q16 pay ', 'text Q16 franc ', 'text Q16 europeen ', 'text Q16 fair ', 'text Q16 etre ', 'text Q16 montr ', 'text Q16 ecolog ', 'text Q16 tax ', 'text Q16 europ ', 'word transport in all the questions ', 'word commun in all the questions ', 'word ecolog in all the questions ', 'word fair in all the questions ', 'word produit in all the questions ', 'word voitur in all the questions ', 'word consomm in all the questions ', 'word etre in all the questions ', 'word energ in all the questions ', 'word utilis in all the questions ', 'transport en commun for all questions ']\n"
     ]
    }
   ],
   "source": [
    "print(features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tB2N_lZr06Mx",
    "outputId": "b8e6dd94-252a-4561-ed7a-13741102f00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sumit = 0\n",
    "for i in range(X.shape[1]) :\n",
    "  sumit += X[:,33][i] \n",
    "print(sumit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZpOIiedEjL9"
   },
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aynTlxu5P4wn"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "pca = decomposition.PCA(n_components=20) \n",
    "\n",
    "pca.fit(X)\n",
    "X = pca.transform(X) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# Code from scikit-learn\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import confusion_matrix    \n",
    "class_names = [\"No dense\",\"Dense\"]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "DN6wO2StrxPt",
    "outputId": "f7a8b086-2aa5-4d21-dbc2-22d369017e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest : training set\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3657e306f428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp_grid_RF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_samples_leaf'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'log2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_grid_RF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done in %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "t0 = time()\n",
    "print(\"Random Forest : training set\")\n",
    "RF=RandomForestClassifier(criterion=\"gini\", random_state=2)\n",
    "p_grid_RF = {'n_estimators': [6,10,20,30,50,100], 'min_samples_leaf': [2,4,6], 'max_features': ['sqrt','log2']}\n",
    "rf = GridSearchCV(estimator=RF, param_grid=p_grid_RF)\n",
    "rf.fit(X_resampled,y_resampled)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(rf.best_params_)\n",
    "print(\"Score : \",rf.score(X_test,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "nUsGqhodzHZg",
    "outputId": "6015643c-d7f7-408e-eea0-e5704855991d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.956 0.044]\n",
      " [0.916 0.084]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEYCAYAAADGepQzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "  \n",
    "#confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test,rf.predict(X_test))\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubKgULNNJL_I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vezqowMmzaEG",
    "outputId": "29ff9473-c9fd-4dab-9b9e-1fb436f7c6be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108158, 30)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIqRbbrY_H6G"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "id": "UfbfiePe_Jat",
    "outputId": "00fbb6f6-1096-4aae-a33f-262dbe989bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA\n",
      "done in 1.845s\n",
      "Average and std CV score : 0.5684184019086465 +- 0.0010100029795813673\n",
      "Score :  0.5956078741715303\n",
      " \n",
      "Normalized confusion matrix\n",
      "[[0.602 0.398]\n",
      " [0.454 0.546]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc84VyAOoc84VyAOoc84V6P8BIEIRFs18SpgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA\n",
      "done in 0.736s\n",
      "Average and std CV score : 0.5030510961996679 +- 0.0005941903772289466\n",
      "Score :  0.15085567316252843\n",
      " \n",
      "Normalized confusion matrix\n",
      "[[0.042 0.958]\n",
      " [0.04  0.96 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEYCAYAAADGepQzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZGhmBjgZmpkBToZmZgD8fxcoC1FxSmjHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LDA & QDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# LDA\n",
    "print(\"LDA\")\n",
    "t0 = time()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_score = cross_val_score(lda,X=X_resampled, y=y_resampled,cv=5)\n",
    "lda.fit(X_resampled,y_resampled)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Average and std CV score : {0} +- {1}\".format(lda_score.mean(), lda_score.std() ))\n",
    "print(\"Score : \",lda.score(X_test,y_test))\n",
    "print(\" \")\n",
    "\n",
    "#confusion_matrix\n",
    "y_pred = lda.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#QDA\n",
    "print(\"QDA\")\n",
    "t0 = time()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda_score = cross_val_score(qda,X=X_resampled, y=y_resampled,cv=5)\n",
    "qda.fit(X_resampled,y_resampled)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Average and std CV score : {0} +- {1}\".format(qda_score.mean(), qda_score.std() ))\n",
    "print(\"Score : \",qda.score(X_test,y_test))\n",
    "print(\" \")\n",
    "\n",
    "#confusion_matrix\n",
    "y_pred = qda.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "5lYIe5iiDI6n",
    "outputId": "90046fc8-b03c-43fb-9385-245de26ff0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4dd0ec3983b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Nested CV with parameter optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mDT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mnested_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "t0 = time()\n",
    "Tree = DecisionTreeClassifier(criterion=\"gini\",random_state=0,max_depth=10)\n",
    "#Tree.fit(X_train,y_train)\n",
    "p_grid = {'min_samples_leaf': range(2,20)}\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# Nested CV with parameter optimization\n",
    "DT = GridSearchCV(estimator=Tree, param_grid=p_grid, cv=inner_cv)\n",
    "DT.fit(X_train,y_train)\n",
    "nested_score = cross_val_score(DT, X=X_train, y=y_train, cv=outer_cv)\n",
    "print(DT.best_params_)\n",
    "# Average accuracy\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Average and std CV score : {0} +- {1}\".format(nested_score.mean(), nested_score.std() ))\n",
    "print(\"Score : \",DT.score(X_test,y_test))\n",
    "print(\" \")\n",
    "\n",
    "#confusion_matrix\n",
    "y_pred = DT.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wF9O6a7_ERod"
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "print(\"Decision Tree with Bagging\")\n",
    "p_grid_tree = {'min_samples_leaf': [2,3,4,5,6,10],'min_samples_split': [2,3,4,5,6]} \n",
    "grid_tree = GridSearchCV(estimator=Tree, param_grid=p_grid_tree, scoring=\"precision\", cv=5)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "Tree2 = DecisionTreeClassifier(criterion=\"gini\", min_samples_leaf=grid_tree.best_params_['min_samples_leaf'],  random_state=0,max_depth=5)\n",
    "p_grid_bagging = {'n_estimators': [500,1000]}      \n",
    "bag=BaggingClassifier(base_estimator=Tree2, random_state=0, max_samples=0.5)\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "Bagg = GridSearchCV(estimator=bag, param_grid=p_grid_bagging, cv=inner_cv, scoring=\"precision\")\n",
    "nested_score = cross_val_score(Bagg, X=X_train, y=y_train,scoring=\"accuracy\", cv=outer_cv)\n",
    "Bagg.fit(X_train,y_train)\n",
    "print(\"Average and std Cv score : {0} +- {1}\".format(nested_score.mean(), nested_score.std() ))\n",
    "\n",
    "grid_bag = GridSearchCV(estimator=bag, param_grid=p_grid_bagging, scoring=\"accuracy\", cv=5)\n",
    "grid_bag.fit(X_train, y_train)\n",
    "print(\"Best Score: {}\".format(grid_bag.best_score_))\n",
    "print(\"Best params: {}\".format(grid_bag.best_params_))\n",
    "print(\"Score : \",grid_bag.score(X_test,y_test))\n",
    "print(\" \")\n",
    "\n",
    "#confusion_matrix\n",
    "y_pred = grid_bag.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#y = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "colab_type": "code",
    "id": "nlgupmd_BMLV",
    "outputId": "d0004470-ec19-4823-dab7-78983880ae84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5e4d81eb1571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Nested CV with parameter optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mLSVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLsvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnested_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mLSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average and std Nested Cv score : {0} +- {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Linear SVM and Non-Linear SVM\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Linear SVM\n",
    "print(\"Linear SVM\")\n",
    "t0 = time()\n",
    "p_grid = {'C': [1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,1e1]}\n",
    "Lsvm = LinearSVC(class_weight='balanced')\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# Nested CV with parameter optimization\n",
    "LSVM = GridSearchCV(estimator=Lsvm, param_grid=p_grid, cv=inner_cv)\n",
    "nested_score = cross_val_score(LSVM, X=X_resampled, y=y_resampled, cv=outer_cv)\n",
    "LSVM.fit(X_resampled, y_resampled)\n",
    "print(\"Average and std Nested Cv score : {0} +- {1}\".format(nested_score.mean(), nested_score.std() ))\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Score : \",LSVM.score(X_test,y_test))\n",
    "print(\" \")\n",
    "\n",
    "# confusion_matrix\n",
    "y_pred=LSVM.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Non-linear SVM\n",
    "print(\"Non-linear SVM\")\n",
    "t0 = time()\n",
    "p_grid = {'C': [1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,1e1]}\n",
    "svm = SVC(kernel = 'poly')\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# Nested CV with parameter optimization\n",
    "NLSVM = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "nested_score = cross_val_score(NLAVM, X=X_train, y=y_train, cv=outer_cv)\n",
    "NLSVM.fit(X_train,y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Average and std Nested Cv score : {0} +- {1}\".format(nested_score.mean(), nested_score.std() ))\n",
    "print(\"Score : \",NLSVM.score(X_test,y_test))\n",
    "print(\" \")\n",
    "      \n",
    "# confusion_matrix\n",
    "y_pred=NLSVM.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECkUdqBKYwH3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PD4_YCtBBDGp"
   },
   "outputs": [],
   "source": [
    "# features' importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ERT = ExtraTreesClassifier(n_estimators=1000, random_state=0)\n",
    "ERT.fit(X_train, y_train)\n",
    "importances = ERT.feature_importances_\n",
    "#revers indices\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "''''\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances ERT\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QyZ9FBSxSCC"
   },
   "outputs": [],
   "source": [
    "print\n",
    "for f in range(X.shape[1]):\n",
    "    print(str(f) + \". \" + names[indices[f]] + str(fit.scores_[indices[f]]))\n",
    "    if fit.scores_[indices[f]]>0.02:\n",
    "        FeatureIndList.append(indices[f])\n",
    "        \n",
    "print(X[:,FeatureIndList].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJZtHbdiQfJd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "load_data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
